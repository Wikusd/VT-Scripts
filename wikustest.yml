# Velocity Trade
# Network Debug Script Version: 1
# First Release Date: 2022-09-09
# Last Modified Date: 2022-09-15
# Author: Wikus Du Plessis
# Description: Run network debug tests on the remote server and retrieve logs, enable sharing of network debugging information with third parties.

# Ansible Playbook
- name: Ansible_Playbook_Test
  hosts: all
  tasks:

# Start the tcpdump service with filter in an async state. The dump will run in the background while we do other high-level network traffic tests.
    - name: starting_tcpdump
      async: '{{duration}}'
      poll: 0
      command: tcpdump -G {{duration}} -W 1 -w ~/{{cap_file}}.pcap host {{destination_ip}}
      register: async_tcpdump

# Run a stock standard ICMP ping
    - name: starting_ping 
      shell: ping {{destination_ip}} -c {{count}} -D > ~/probe.{{cap_file}}
      register: ping_result

# Run My Trace Route utility on specify port/ip/count & protocol.
    - name: starting_mtr 
      shell: mtr {{destination_ip}} -C {{count}} --{{protocol}} --report >> ~/probe.{{cap_file}}
      ignore_errors: true
      register: mtrrc
      failed_when: mtrrc.rc not in [ 0, 1 ]

# Check if remote port is open and currently in an active listening state. Similiar to the telnet port check.
    - name: checking_remote_port
      wait_for:
        host: "{{destination_ip}}"
        port: "{{destination_port}}"
        state: started         # Port should be open
        delay: 0               # No wait before first check (sec)
        timeout: 5             # Stop checking after timeout (sec)
      ignore_errors: yes

    - name: probe_output
      shell: cat ~/probe.{{cap_file}};

    - name: compress_captured_file
      command: tar -czvf ansible_tcp_logs{{cap_file}}.tar.gz ~/{{cap_file}}.pcap ~/probe.{{cap_file}}
      warn: false
      


# ///TODO/// 
# 1) Send email with attached log files to specified email addresses. Will require SMTP authentication.
# 2) Add additional troubleshooting tools to expand the scope of debug to disks, CPU and Memory consumption. Alternatively, create seperate jobs consisting of the following.
#    Can be consolidated into a single work-flow for modular deployment and execution.